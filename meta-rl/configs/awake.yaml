# General
# -------
# Name of the environment.
env-name: "awake"

# Additional parameters for the environment (eg. bound for task sampling).
env-kwargs:
  train: true
  max_time: 100

# Discount factor gamma.
gamma: 1.0

# Discount factor lambda used in "Generalized Advantage Estimation" (GAE).
gae-lambda: 0.99

# If "true", then the first order approximation of MAML is applied.
first-order: true

# Policy network
# --------------
# Number of hidden units in each layer.
hidden-sizes: [64, 64]

# Non-linear activation function to apply after each hidden layer.
nonlinearity: "tanh"

# Task-specific
# -------------
# Number of trajectories to sample for each task.
fast-batch-size: 16

# Number of gradient steps in the inner loop / fast adaptation.
# number of trajectories*fast_batch_size
num-steps: 4

# Step size for each gradient step in the inner loop / fast adaptation.
fast-lr: 0.01

# Optimization
# ------------
# Number of outer-loop updates (i.e. number of batches of tasks).
num-batches: 500

# Number of tasks in each batch of tasks.
meta-batch-size: 8

# TRPO-specific
# -------------
# Size of the trust-region.
max-kl: 1.0e-3

# Number of iterations of Conjugate Gradient.
cg-iters: 80

# Value of the damping in Conjugate Gradient.
cg-damping: 1.0e-5

# Maximum number of steps in the line search.
ls-max-steps: 100

# Ratio to use for backtracking during the line search.
ls-backtrack-ratio: 0.6
